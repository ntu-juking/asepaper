% !TEX root = CI_Adoption.tex

\section{Introduction}

%It is not everyday that software engineering experiences a paradigm shift.
The \DO movement, made popular in recent years, is a paradigm shift 
%according to many
\cite{degrandis2011devops, loukides2012devops, humble2011enterprises, 
roche2013adopting}.
%\DO 
It aims to get changes into production as quickly as 
possible, without compromising software quality.
While no standard definitions exist (the term is often overloaded), here
we refer to \DO as a culture that emphasizes \emph{automation of the 
process of building, testing, and deploying software}.
In practice, \DO is supported by a multitude of tools for configuration 
management, cloud-based continuous integration, and automated deployment,
which enjoy widespread open-source~\cite{Hilton2016} and industrial 
adoption~\cite{rightscale, hilton2016continuous}.

In this study we focus on Continuous Integration (CI), the key enabler of \DO.
CI is a well known concept in Extreme Programming, promulgated in 
Martin Fowler's 2000 blog post~\cite{fowler2000continuous}.
As a practice, CI is seeing broad adoption with the increasing popularity
of the \GH pull-based development model~\cite{gousios2014exploratory}
and the plethora of open-source, \GH-compatible, cloud-based CI 
tools,\footnote{\url{https://github.com/integrations/feature/continuous-integration}}
such as \Tvis, \CB, and \CCI.
In a decentralized, social coding context such as \GH, CI is particularly relevant. 
By automatically building and testing a project's code base, in isolation, 
with each incoming code change (\ie push commit, pull request), CI 
has the potential to: (i)~speed up development (code change throughput)
\cite{Stolberg, pham2013creating, Hilton2016};
(ii)~help maintain code quality~\cite{VasilescuYWDF15, gousios2015work}.
Clearly, CI promises to be a disruptive technology in distributed software
development.
%However, despite its large scale adoption, we know relatively little about 
%the state of practice in using CI technology and the extent to which 
%developers are benefitting from its power.

For it to be effective, CI must allow for a seamless back and forth between
development, testing (\eg unit, integration, code review), and deployment. 
However, the road to efficiency is riddled with choices and trade-offs.
For example, working in large increments may lead to more meaningful
change sets, but it may also complicate synchronization between team 
members and, if necessary, reverting changes.
More frequent changes facilitate merging, but they also require more 
computing infrastructure for CI, since by default the code is built and all 
tests are executed with \emph{every} change.
Moreover, while CI runs on smaller, more frequent changes would provide 
earlier feedback on potential problems, they may also lead to process 
``noise'', where developers start to ignore the CI build status due to 
information overload, irrespective of whether the build is clean or 
broken~\cite{DeadCI}.

Several CI ``best practices'' have been proposed, \eg by Fowler in his 
influential blog post~\cite{fowler2000continuous}, such as 
\emph{Everyone Commits To the Mainline Every Day}, 
\emph{Fix Broken Builds Immediately},
and \emph{Keep the Build Fast}.
However, despite the large scale adoption of CI, we know relatively little 
about the state of the practice in using this technology and whether 
developers are aligning their practices with Fowler's proposed ``best practices".
Using CI seems apparently beneficial, especially since many others are using it.
But how much disruption does the transition to CI cause?
And how do teams change their workflows to accommodate CI?
Such knowledge can help developers to optimize their practices, project 
maintainers to make informed decisions about adopting CI, and 
researchers and tool builders to identify areas in need of attention.

In this paper we report on a study of a sample of \GH open-source 
software projects that adopted \Tvis, by far the most popular 
CI infrastructure used on \GH~\cite{Hilton2016}.
In particular, we focus on the \emph{transition from no CI to using 
T{\footnotesize RAVIS} CI}, and investigate how development practices 
changed following the adoption of \Tvis.
To this end, we operationalize practices in three main aspects of 
distributed development, related to code changes, issue tracking, 
and testing.
To evaluate the effect of an intervention, in our case adoption of
\Tvis, on the transition toward expected behaviors in the above 
three practices (measured from trace data of \GH repositories),
we introduce \emph{regression discontinuity design analyses}.
Applying this methodology to hundreds of open-source Java 
projects, appropriately selected, we find that:


\begin{itemize}

\item Following CI adoption there are downward trends in commit churn, 
for ca. 10\% of projects (for ca. 86\% no statistical evidence for a trend 
could be found, and for ca. 4\% the trend is upwards). 
This downward trend is non-existent before the adoption. 
This is in agreement with Fowler's ``best practices", although 
probably to a much lesser extent than expected.

\item The commit frequency for both merge and non-merge commits does 
not change substantially for most projects, but for 20\% of them it increases
after CI adoption, but returns back down with time.
This is not in apparent agreement with Fowler's ``best practices".

\item There is an increasing trend in the number of automatic tests 
executed per build after CI adoption, as expected.

\item There are significantly more issues submitted after CI is 
adopted than before.

\end{itemize}


The rest of this paper starts by developing the research questions 
pertaining to adoption of CI and its impact on developers' practices 
(Sect.~\ref{sec:background}), then discusses the methods used to collect 
and analyze the data (Sect.~\ref{sec:method}), presents the results 
(Sect.~\ref{sec:results}), reviews the related work (Sect.~\ref{sec:rw}),
assesses threats to validity (Sect.~\ref{sec:threats}), and concludes 
(Sect.~\ref{sec:conc}).

%In what follows, we tell this paper's story in a carefully crafted, yet mostly standard multisectioned format, beginning with the inimitable background and theory section, followed by an exemplary part on methodology, culminating in our tight results and logical discussion, with our long reaching conclusions, and the unavoidable threats to validity section bringing up the rear. \bv{Change this paragraph}

%sought to examine the extent to which best practices 
%of CI are actually transitioned to and followed, after CI adoption in online 
%software development projects. 
%We focus on three major aspects of modern development: practices 
%related to code changes, code testing, and code reviews \bv{Are we still doing reviews?}, and operationalize them into measures for them which we observe from trace data of GitHub repositories.
%We introduce regression discontinuity design analyses in order to 
%evaluate the effect of an intervention, in our case CI adoption, on the 
%transition toward expected behaviors in the above three practices.
%Applying those methods to hundreds of projects, appropriately selected, 
%we find that:

%https://sethrobertson.github.io/GitBestPractices/

%Devops, or bringing development and build/release activities in the same framework can bring changes in the product to the user-plane more quickly. For it to be effective, the technology that implements these ideas has to allow for a seamless back and forth between development, integration, code testing review, and release. 

%Continuous Integration is the part of devops that seamlessly builds, tests, and integrates developer changes, and performs any pre-specified testing. CI (\eg Travis CI, Jenkins CI, Hudson CI), if implemented properly, can benefit the distributed software development process, in particular code change throughput~\cite{Stolberg} and some aspects of code quality~\cite{VasilescuYWDF15}. It is a disruptive technology, in that it can scale up distributed development without noticeable diminishment in quality.

%Proper implementation is key here, otherwise the benefits may not be felt, and the technology may become a drag on resources, since it subsumes continuous builds and testing. 
%This is particularly true in team environments, where it falls to each individual developer to keep up with project specific implementation policies.
%For that reason, Martin Fowler wrote an article on CI best practices~\cite{}, which has been very influential and in many projects there are expectations that those practices define CI and that they will be followed.~\cite{}
%In particular, those practices are: Maintain a Single Source Repository,  Automate the Build, Make Your Build Self-Testing, Everyone Commits To the Mainline Every Day, Every Commit Should Build the Mainline on an Integration Machine, Fix Broken Builds Immediately, Keep the Build Fast, Test in a Clone of the Production Environment, Make it Easy for Anyone to Get the Latest Executable, Everyone can see what's happening, and Automate Deployment.
%But to what extent are they followed in practice?
