% !TEX root = CI_Adoption.tex

\section{Introduction}

%It is not everyday that software engineering experiences a paradigm shift.
The \DO movement, made popular in recent years, is a paradigm shift 
%according to many
\cite{degrandis2011devops, loukides2012devops, humble2011enterprises, 
roche2013adopting}.
%\DO 
It aims to get changes into production as quickly as 
possible, without compromising software quality.
While no standard definitions exist (the term is often overloaded), here
we refer to \DO as a culture that emphasizes \emph{automation of the 
processes of building, testing, and deploying software}.
In practice, \DO is supported by a multitude of tools for configuration 
management, cloud-based continuous integration, and automated deployment,
which enjoy widespread open-source~\cite{Hilton2016} and industrial 
adoption~\cite{rightscale, hilton2016continuous}.

In this study we focus on Continuous Integration (CI), the key enabler of \DO.
CI is a well known concept in Extreme Programming, promulgated in 
Martin Fowler's 2000 blog post~\cite{fowler2000continuous}.
As a practice, CI is seeing broad adoption with the increasing popularity
of the \GH pull-based development model~\cite{gousios2014exploratory}
and the plethora of open-source, \GH-compatible, cloud-based CI 
tools,\footnote{\url{https://github.com/integrations/feature/continuous-integration}}
such as \Tvis, \CB, and \CCI.
In a decentralized, social coding context such as \GH, CI is particularly relevant. 
By automatically building and testing a project's code base, in isolation, 
with each incoming code change (\ie push commit, pull request), CI 
has the potential to: (i)~speed up development (code change throughput)
\cite{Stolberg, pham2013creating, Hilton2016};
(ii)~help maintain code quality~\cite{VasilescuYWDF15, gousios2015work}.
Clearly, CI promises to be a disruptive technology in distributed software
development.
%However, despite its large scale adoption, we know relatively little about 
%the state of practice in using CI technology and the extent to which 
%developers are benefitting from its power.

For it to be effective, CI must allow for a seamless back and forth between
development, testing (\eg unit, integration, code review), and deployment. 
However, the road to efficiency is riddled with choices and trade-offs.
For example, working in large increments may lead to more meaningful
change sets, but it may also complicate synchronization between team 
members and, if necessary, reverting changes.
Conversely, more frequent changes facilitate merging, but they also require more 
computing infrastructure for CI, since by default the code is built and all 
tests are executed with \emph{every} change.
Moreover, while CI runs on smaller changes, more frequent ones would provide 
earlier feedback on potential problems, they may also lead to process 
``noise'', where developers start to ignore the CI build status due to 
information overload, irrespective of whether the build is clean or 
broken~\cite{DeadCI}.

Several CI ``best practices'' have been proposed, \eg by Fowler in his 
influential blog post~\cite{fowler2000continuous}, such as 
\emph{Everyone Commits To the Mainline Every Day}, 
\emph{Fix Broken Builds Immediately},
and \emph{Keep the Build Fast}.
However, despite the large scale adoption of CI, we know relatively little 
about the state of the practice in using this technology and whether 
developers are aligning their practices with Fowler's proposed ``best practices".
%Using CI seems apparently beneficial, especially since many others are using it.
%But how much disruption does the transition to CI cause?
%And how do teams change their workflows to accommodate CI?
Such knowledge can help developers to optimize their practices, project 
maintainers to make informed decisions about adopting CI, and 
researchers and tool builders to identify areas in need of attention.

In this paper we report on a study of a large sample of \GH open-source 
projects that adopted \Tvis, by far the most popular 
CI infrastructure used on \GH~\cite{Hilton2016}.
In particular, we focus on the \emph{transition to using 
T{\footnotesize RAVIS} CI}, and investigate how development practices 
changed following this shift.
To this end, we introduce \emph{regression 
discontinuity design analyses} to quantitatively evaluate the effect of an intervention, in our case 
adoption of \Tvis, on the transition toward expected behaviors in the 
above three practices (measured from trace data in thousands of 
\GH projects, appropriately selected).
Qualitatively, to help essentialize the quantitative results, we survey a 
sample of \GH developers about their experiences with adopting \Tvis. 
Applying this mixed methodology, we find that:

\bv{This needs to be updated}
\begin{itemize}

\item the increasing number of merge commits aligns with the the ``commit often'' guideline of Fowler, but is likely to be further encouraged by the shift to a more distributed workflow with multiple branches and pull requests;
\item the ``commit small'' guideline, however, is followed only to some extent but the differences between the projects are more important than adherence to this guideline;
\item the expected increasing trend in the number of closed pull requests manifests itself after the introduction of \Tvis, and even then only after the initial plateau period;
\item the pull request latency increases  despite the code changes becoming smaller;
\item while the number of issues closed increases, this trend is unexpectedly slowed down by \Tvis
\item after the adjustments for the automated testing, the debugging complexity seems to increase.
\end{itemize}


The rest of this paper starts by developing the research questions 
pertaining to adoption of CI and its impact on developer practices 
(Sect.~\ref{sec:background}), then discusses the methods used to collect 
and analyze the data (Sect.~\ref{sec:method}), presents the results 
(Sect.~\ref{sec:results}), reviews the related work (Sect.~\ref{sec:rw}),
assesses threats to validity (Sect.~\ref{sec:threats}), and concludes 
(Sect.~\ref{sec:conc}).

%In what follows, we tell this paper's story in a carefully crafted, yet mostly standard multisectioned format, beginning with the inimitable background and theory section, followed by an exemplary part on methodology, culminating in our tight results and logical discussion, with our long reaching conclusions, and the unavoidable threats to validity section bringing up the rear. \bv{Change this paragraph}

%sought to examine the extent to which best practices 
%of CI are actually transitioned to and followed, after CI adoption in online 
%software development projects. 
%We focus on three major aspects of modern development: practices 
%related to code changes, code testing, and code reviews \bv{Are we still doing reviews?}, and operationalize them into measures for them which we observe from trace data of GitHub repositories.
%We introduce regression discontinuity design analyses in order to 
%evaluate the effect of an intervention, in our case CI adoption, on the 
%transition toward expected behaviors in the above three practices.
%Applying those methods to hundreds of projects, appropriately selected, 
%we find that:

%https://sethrobertson.github.io/GitBestPractices/

%Devops, or bringing development and build/release activities in the same framework can bring changes in the product to the user-plane more quickly. For it to be effective, the technology that implements these ideas has to allow for a seamless back and forth between development, integration, code testing review, and release. 

%Continuous Integration is the part of devops that seamlessly builds, tests, and integrates developer changes, and performs any pre-specified testing. CI (\eg Travis CI, Jenkins CI, Hudson CI), if implemented properly, can benefit the distributed software development process, in particular code change throughput~\cite{Stolberg} and some aspects of code quality~\cite{VasilescuYWDF15}. It is a disruptive technology, in that it can scale up distributed development without noticeable diminishment in quality.

%Proper implementation is key here, otherwise the benefits may not be felt, and the technology may become a drag on resources, since it subsumes continuous builds and testing. 
%This is particularly true in team environments, where it falls to each individual developer to keep up with project specific implementation policies.
%For that reason, Martin Fowler wrote an article on CI best practices~\cite{}, which has been very influential and in many projects there are expectations that those practices define CI and that they will be followed.~\cite{}
%In particular, those practices are: Maintain a Single Source Repository,  Automate the Build, Make Your Build Self-Testing, Everyone Commits To the Mainline Every Day, Every Commit Should Build the Mainline on an Integration Machine, Fix Broken Builds Immediately, Keep the Build Fast, Test in a Clone of the Production Environment, Make it Easy for Anyone to Get the Latest Executable, Everyone can see what's happening, and Automate Deployment.
%But to what extent are they followed in practice?
